import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import OneHotEncoder, StandardScaler, MaxAbsScaler
from sklearn.impute import SimpleImputer
from sklearn.linear_model import RidgeCV, SGDRegressor
from sklearn.metrics import r2_score, mean_squared_error
from sklearn.neural_network import MLPRegressor


# import data
movies = pd.read_csv("cleaned_movies.csv")

##  Fitting Models 

# LR (dependent variable is tickets.sold without gross)
# Target
movies["tickets_sold"] = pd.to_numeric(movies["tickets_sold"], errors="coerce")

# Splitting the date up
movies["release_date"] = pd.to_datetime(movies["release_date"], errors="coerce")
movies["release_year"]  = movies["release_date"].dt.year
movies["release_month"] = movies["release_date"].dt.month

# Predictors
predictors = ["release_year", "release_month", "Distributor", "Genre", 
              "MPAA","title_has_man", "title_has_love", "title_has_life"]
predictors = [c for c in predictors if c in movies.columns]

# compose X and y
X = movies[predictors].copy()
y = movies["tickets_sold"]

cat_cols = [c for c in ["Distributor","Genre","MPAA"] if c in X.columns]
num_cols = [c for c in ["release_year","release_month"] if c in X.columns]
bin_cols = [c for c in ["title_has_man","title_has_love","title_has_life"] if c in X.columns]

preproc_sparse = ColumnTransformer([
    ("num", Pipeline(steps=[
        ("imp", SimpleImputer(strategy="median")),
        ("sc", StandardScaler(with_mean=False))  # keep sparse
    ]), num_cols),
    ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=True), cat_cols),
    ("bin", "passthrough", bin_cols),
], sparse_threshold=1.0)

# Final scale for sparse matrices
prep = Pipeline([
    ("ct", preproc_sparse),
    ("scale", MaxAbsScaler())   # robust, keeps sparsity
])

# Split once for fair holdout
X_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.2, random_state=42)

def print_results(name, pipe):
    # 3-fold CV RMSE on original scale (fast)
    try:
        cv = -cross_val_score(pipe, X, y, cv=3, scoring="neg_root_mean_squared_error")
    except ValueError:
        from sklearn.metrics import make_scorer
        cv = -cross_val_score(pipe, X, y, cv=3,
                              scoring=make_scorer(lambda yt, yp: mean_squared_error(yt, yp),
                                                  greater_is_better=False))
    pipe.fit(X_tr, y_tr)
    y_hat = pipe.predict(X_te)
    rmse = mean_squared_error(y_te, y_hat)
    r2   = r2_score(y_te, y_hat)
    print(f"{name:12s}  CV_RMSE={cv.mean():.3f} (±{cv.std():.3f})  Holdout_RMSE={rmse:.3f}  Holdout_R2={r2:.3f}")

# 1) Ridge CV
ridge = Pipeline([
    ("prep", prep),
    ("model", RidgeCV(alphas=np.logspace(-3, 3, 9), cv=3))
])
print_results("RidgeCV", ridge)

# 2) SGDRegressor with elasticnet
sgd_en = Pipeline([
    ("prep", prep),
    ("model", SGDRegressor(
        loss="squared_error",
        penalty="elasticnet",
        alpha=1e-4,          # overall regularization strength
        l1_ratio=0.2,        # L1 portion
        max_iter=3000,
        tol=1e-3,
        early_stopping=True,
        n_iter_no_change=5,
        random_state=42
    ))
])
print_results("SGD-EN", sgd_en)


# neural network

mask = y.notna() & X.notna().all(axis=1)
X_use, y_use = X.loc[mask].copy(), y.loc[mask].astype(float).copy()

cat_cols = [c for c in ["Distributor","Genre","MPAA"] if c in X_use.columns]
num_cols = [c for c in ["release_year","release_month"] if c in X_use.columns]
bin_cols = [c for c in ["title_has_man","title_has_love","title_has_life"] if c in X_use.columns]

# MLP
preproc_dense = ColumnTransformer([
    ("num", Pipeline(steps=[
        ("imp", SimpleImputer(strategy="median")),
        ("sc", StandardScaler())
    ]), num_cols),
    ("cat", OneHotEncoder(handle_unknown="ignore", sparse_output=False), cat_cols),
    ("bin", "passthrough", bin_cols),
], remainder="drop")

mlp = MLPRegressor(
    hidden_layer_sizes=(32,),      # shallow net
    activation="relu",
    alpha=1e-4,                    # L2 reg
    learning_rate_init=1e-3,
    max_iter=400,
    early_stopping=True,
    n_iter_no_change=10,
    random_state=42
)

pipe = Pipeline([("prep", preproc_dense), ("model", mlp)])

# 5-fold CV RMSE
try:
    cv_rmse = -cross_val_score(pipe, X_use, y_use, cv=5, scoring="neg_root_mean_squared_error")
except ValueError:
    from sklearn.metrics import make_scorer
    cv_rmse = -cross_val_score(
        pipe, X_use, y_use, cv=5,
        scoring=make_scorer(lambda yt, yp: mean_squared_error(yt, yp), greater_is_better=False)
    )

X_tr, X_te, y_tr, y_te = train_test_split(X_use, y_use, test_size=0.2, random_state=42)
pipe.fit(X_tr, y_tr)
y_hat = pipe.predict(X_te)

print("MLP (tickets_sold):")
print("  CV RMSE (mean ± sd): {:.3f} ± {:.3f}".format(cv_rmse.mean(), cv_rmse.std()))
print("  Holdout RMSE:", mean_squared_error(y_te, y_hat))
print("  Holdout R^2 :", r2_score(y_te, y_hat))

pipe_log = Pipeline([("prep", preproc_dense), ("model", mlp)])

# CV on log scale
y_log = np.log1p(y_use)
try:
    cv_rmse_log = -cross_val_score(pipe_log, X_use, y_log, cv=5, scoring="neg_root_mean_squared_error")
except ValueError:
    from sklearn.metrics import make_scorer
    cv_rmse_log = -cross_val_score(
        pipe_log, X_use, y_log, cv=5,
        scoring=make_scorer(lambda yt, yp: mean_squared_error(yt, yp), greater_is_better=False)
    )

X_tr, X_te, y_tr, y_te = train_test_split(X_use, y_use, test_size=0.2, random_state=42)
pipe_log.fit(X_tr, np.log1p(y_tr))
yhat_te = np.expm1(pipe_log.predict(X_te))  # back-transform

print("\nMLP (log1p target → back-transform):")
print("  CV RMSE on log scale (mean ± sd): {:.3f} ± {:.3f}".format(cv_rmse_log.mean(), cv_rmse_log.std()))
print("  Holdout RMSE (original scale):", mean_squared_error(y_te, yhat_te))
print("  Holdout MAE (original scale):", np.mean(np.abs(y_te - yhat_te)))
